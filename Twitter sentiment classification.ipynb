{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id       source      type  \\\n",
       "0  2401  Borderlands  Positive   \n",
       "1  2401  Borderlands  Positive   \n",
       "2  2401  Borderlands  Positive   \n",
       "3  2401  Borderlands  Positive   \n",
       "4  2401  Borderlands  Positive   \n",
       "\n",
       "                                                text  \n",
       "0  im getting on borderlands and i will murder yo...  \n",
       "1  I am coming to the borders and I will kill you...  \n",
       "2  im getting on borderlands and i will kill you ...  \n",
       "3  im coming on borderlands and i will murder you...  \n",
       "4  im getting on borderlands 2 and i will murder ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['id','source','type','text']\n",
    "df = pd.read_csv('twitter_training.csv',names=columns )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74677</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74678</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74679</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74680</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74681</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71982 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id       source      type  \\\n",
       "0      2401  Borderlands  Positive   \n",
       "1      2401  Borderlands  Positive   \n",
       "2      2401  Borderlands  Positive   \n",
       "3      2401  Borderlands  Positive   \n",
       "4      2401  Borderlands  Positive   \n",
       "...     ...          ...       ...   \n",
       "74677  9200       Nvidia  Positive   \n",
       "74678  9200       Nvidia  Positive   \n",
       "74679  9200       Nvidia  Positive   \n",
       "74680  9200       Nvidia  Positive   \n",
       "74681  9200       Nvidia  Positive   \n",
       "\n",
       "                                                    text  \n",
       "0      im getting on borderlands and i will murder yo...  \n",
       "1      I am coming to the borders and I will kill you...  \n",
       "2      im getting on borderlands and i will kill you ...  \n",
       "3      im coming on borderlands and i will murder you...  \n",
       "4      im getting on borderlands 2 and i will murder ...  \n",
       "...                                                  ...  \n",
       "74677  Just realized that the Windows partition of my...  \n",
       "74678  Just realized that my Mac window partition is ...  \n",
       "74679  Just realized the windows partition of my Mac ...  \n",
       "74680  Just realized between the windows partition of...  \n",
       "74681  Just like the windows partition of my Mac is l...  \n",
       "\n",
       "[71982 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "Negative      22542\n",
       "Positive      20832\n",
       "Neutral       18318\n",
       "Irrelevant    12990\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "TomClancysRainbowSix                 2400\n",
       "MaddenNFL                            2400\n",
       "Microsoft                            2400\n",
       "LeagueOfLegends                      2394\n",
       "CallOfDuty                           2394\n",
       "Verizon                              2382\n",
       "CallOfDutyBlackopsColdWar            2376\n",
       "ApexLegends                          2376\n",
       "Facebook                             2370\n",
       "WorldOfCraft                         2364\n",
       "Dota2                                2364\n",
       "NBA2K                                2352\n",
       "TomClancysGhostRecon                 2346\n",
       "Battlefield                          2346\n",
       "FIFA                                 2340\n",
       "Xbox(Xseries)                        2334\n",
       "Overwatch                            2334\n",
       "johnson&johnson                      2328\n",
       "Amazon                               2316\n",
       "PlayStation5(PS5)                    2310\n",
       "HomeDepot                            2310\n",
       "Cyberpunk2077                        2304\n",
       "CS-GO                                2304\n",
       "GrandTheftAuto(GTA)                  2304\n",
       "Hearthstone                          2298\n",
       "Nvidia                               2298\n",
       "Google                               2298\n",
       "Borderlands                          2286\n",
       "PlayerUnknownsBattlegrounds(PUBG)    2274\n",
       "Fortnite                             2274\n",
       "RedDeadRedemption(RDR)               2262\n",
       "AssassinsCreed                       2244\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if isinstance(text, str):  # Check if the value is a string\n",
    "        # Convert text to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove special characters, hyperlinks, and usernames\n",
    "        text = re.sub(r\"http\\S+|www\\S+|@[^\\s]+|\\n|\\r\", \"\", text)\n",
    "        text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "        \n",
    "        # Tokenize text\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords and non-alphabetic tokens\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n",
    "        \n",
    "        # Lemmatize tokens\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "        \n",
    "        # Join tokens back into a cleaned text\n",
    "        cleaned_text = ' '.join(tokens)\n",
    "        return cleaned_text\n",
    "    else:\n",
    "        return ''  # Return empty string for non-string values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         int64\n",
       "source    object\n",
       "type      object\n",
       "text      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_tweet'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "      <td>im getting borderland murder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>coming border kill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>im getting borderland kill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>im coming borderland murder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>im getting borderland murder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id       source      type  \\\n",
       "0  2401  Borderlands  Positive   \n",
       "1  2401  Borderlands  Positive   \n",
       "2  2401  Borderlands  Positive   \n",
       "3  2401  Borderlands  Positive   \n",
       "4  2401  Borderlands  Positive   \n",
       "\n",
       "                                                text  \\\n",
       "0  im getting on borderlands and i will murder yo...   \n",
       "1  I am coming to the borders and I will kill you...   \n",
       "2  im getting on borderlands and i will kill you ...   \n",
       "3  im coming on borderlands and i will murder you...   \n",
       "4  im getting on borderlands 2 and i will murder ...   \n",
       "\n",
       "                  cleaned_tweet  \n",
       "0  im getting borderland murder  \n",
       "1            coming border kill  \n",
       "2    im getting borderland kill  \n",
       "3   im coming borderland murder  \n",
       "4  im getting borderland murder  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df['cleaned_tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF representation:\n",
      "    aa  aaa   ab  abandon  abandoned  abc  ability  able  absolute  \\\n",
      "0  0.0  0.0  0.0      0.0        0.0  0.0      0.0   0.0       0.0   \n",
      "1  0.0  0.0  0.0      0.0        0.0  0.0      0.0   0.0       0.0   \n",
      "2  0.0  0.0  0.0      0.0        0.0  0.0      0.0   0.0       0.0   \n",
      "3  0.0  0.0  0.0      0.0        0.0  0.0      0.0   0.0       0.0   \n",
      "4  0.0  0.0  0.0      0.0        0.0  0.0      0.0   0.0       0.0   \n",
      "\n",
      "   absolutely  ...  zelda  zen  zero  zip  zoe  zombie  zone  zonestreamcx  \\\n",
      "0         0.0  ...    0.0  0.0   0.0  0.0  0.0     0.0   0.0           0.0   \n",
      "1         0.0  ...    0.0  0.0   0.0  0.0  0.0     0.0   0.0           0.0   \n",
      "2         0.0  ...    0.0  0.0   0.0  0.0  0.0     0.0   0.0           0.0   \n",
      "3         0.0  ...    0.0  0.0   0.0  0.0  0.0     0.0   0.0           0.0   \n",
      "4         0.0  ...    0.0  0.0   0.0  0.0  0.0     0.0   0.0           0.0   \n",
      "\n",
      "   zoom  zuckerberg  \n",
      "0   0.0         0.0  \n",
      "1   0.0         0.0  \n",
      "2   0.0         0.0  \n",
      "3   0.0         0.0  \n",
      "4   0.0         0.0  \n",
      "\n",
      "[5 rows x 5000 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize TfidfTransformer to create TF-IDF representation from BoW\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "count_vectorizer = CountVectorizer(max_features=5000)  # Limit to top 5000 features\n",
    "bow_matrix = count_vectorizer.fit_transform(tweets)\n",
    "\n",
    "# Fit and transform the BoW matrix to generate TF-IDF representation\n",
    "tfidf_matrix = tfidf_transformer.fit_transform(bow_matrix)\n",
    "\n",
    "# Get the feature names (words)\n",
    "feature_names = count_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame to display the TF-IDF representation\n",
    "tfidf_df = pd.DataFrame.sparse.from_spmatrix(tfidf_matrix, columns=feature_names)\n",
    "\n",
    "# Displaying the TF-IDF DataFrame\n",
    "print(\"TF-IDF representation:\")\n",
    "print(tfidf_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set - X: (59196, 5000)  y: (59196,)\n",
      "Testing set - X: (14800, 5000)  y: (14800,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming tfidf_matrix is your TF-IDF representation and data['sentiment'] contains labels\n",
    "\n",
    "# Splitting TF-IDF matrix and labels into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, df['type'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Displaying the shapes of the splits\n",
    "print(\"Training set - X:\", X_train.shape, \" y:\", y_train.shape)\n",
    "print(\"Testing set - X:\", X_test.shape, \" y:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6757432432432432\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.70      0.49      0.58      2696\n",
      "    Negative       0.67      0.80      0.73      4380\n",
      "     Neutral       0.67      0.61      0.64      3605\n",
      "    Positive       0.68      0.73      0.70      4119\n",
      "\n",
      "    accuracy                           0.68     14800\n",
      "   macro avg       0.68      0.66      0.66     14800\n",
      "weighted avg       0.68      0.68      0.67     14800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Logistic Regression model\n",
    "logistic_model = LogisticRegression(max_iter=1000)  # Increase max_iter if necessary\n",
    "\n",
    "# Train the model on the training data\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = logistic_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4250675675675676\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.28      0.93      0.43      2696\n",
      "    Negative       0.75      0.30      0.43      4380\n",
      "     Neutral       0.76      0.25      0.37      3605\n",
      "    Positive       0.52      0.38      0.44      4119\n",
      "\n",
      "    accuracy                           0.43     14800\n",
      "   macro avg       0.58      0.46      0.42     14800\n",
      "weighted avg       0.60      0.43      0.42     14800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Gaussian Naive Bayes classifier\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "# Train the model on the training data\n",
    "naive_bayes.fit(X_train.toarray(), y_train)  # Convert sparse matrix to array for GaussianNB\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = naive_bayes.predict(X_test.toarray())  # Convert sparse matrix to array for predictions\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1850/1850 [==============================] - 316s 169ms/step - loss: 0.0000e+00 - accuracy: 0.4543 - val_loss: 0.0000e+00 - val_accuracy: 0.4781\n",
      "Epoch 2/5\n",
      "1850/1850 [==============================] - 328s 177ms/step - loss: 0.0000e+00 - accuracy: 0.4757 - val_loss: 0.0000e+00 - val_accuracy: 0.4781\n",
      "Epoch 3/5\n",
      "1850/1850 [==============================] - 328s 177ms/step - loss: 0.0000e+00 - accuracy: 0.4757 - val_loss: 0.0000e+00 - val_accuracy: 0.4781\n",
      "Epoch 4/5\n",
      "1850/1850 [==============================] - 342s 185ms/step - loss: 0.0000e+00 - accuracy: 0.4757 - val_loss: 0.0000e+00 - val_accuracy: 0.4781\n",
      "Epoch 5/5\n",
      "1850/1850 [==============================] - 349s 188ms/step - loss: 0.0000e+00 - accuracy: 0.4757 - val_loss: 0.0000e+00 - val_accuracy: 0.4781\n",
      "463/463 [==============================] - 13s 27ms/step - loss: 0.0000e+00 - accuracy: 0.4781\n",
      "Accuracy: 0.47810810804367065\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have text data in 'data['tweet content']' and labels in 'data['sentiment']'\n",
    "\n",
    "# Tokenize and pad sequences\n",
    "max_features = 10000  # Maximum number of words to consider\n",
    "max_len = 100  # Maximum length of sequences\n",
    "tokenizer = Tokenizer(num_words=max_features, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(df['cleaned_tweet'])\n",
    "sequences = tokenizer.texts_to_sequences(df['type'])\n",
    "X = pad_sequences(sequences, maxlen=max_len)\n",
    "y = df['type']\n",
    "\n",
    "\n",
    "# Splitting into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming 'y_train' and 'y_test' are your string labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "# Building RNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=max_len))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Training the RNN model\n",
    "model.fit(X_train, y_train_encoded, epochs=5, batch_size=32, validation_data=(X_test, y_test_encoded))\n",
    "\n",
    "# Evaluate on test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test_encoded)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1850/1850 [==============================] - 567s 302ms/step - loss: 0.0000e+00 - accuracy: 0.3037 - val_loss: 0.0000e+00 - val_accuracy: 0.2959\n",
      "Epoch 2/5\n",
      "1850/1850 [==============================] - 542s 293ms/step - loss: 0.0000e+00 - accuracy: 0.3037 - val_loss: 0.0000e+00 - val_accuracy: 0.2959\n",
      "Epoch 3/5\n",
      "1850/1850 [==============================] - 539s 291ms/step - loss: 0.0000e+00 - accuracy: 0.3037 - val_loss: 0.0000e+00 - val_accuracy: 0.2959\n",
      "Epoch 4/5\n",
      "1850/1850 [==============================] - 920s 497ms/step - loss: 0.0000e+00 - accuracy: 0.3037 - val_loss: 0.0000e+00 - val_accuracy: 0.2959\n",
      "Epoch 5/5\n",
      "1850/1850 [==============================] - 557s 301ms/step - loss: 0.0000e+00 - accuracy: 0.3037 - val_loss: 0.0000e+00 - val_accuracy: 0.2959\n",
      "463/463 [==============================] - 42s 91ms/step - loss: 0.0000e+00 - accuracy: 0.2959\n",
      "Accuracy: 0.295945942401886\n"
     ]
    }
   ],
   "source": [
    "# Building LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=max_len))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(16))  # Last layer without return_sequences=True\n",
    "model.add(Dense(1, activation='softmax'))  # Output layer for classification\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Training the LSTM model\n",
    "model.fit(X_train, y_train_encoded, epochs=5, batch_size=32, validation_data=(X_test, y_test_encoded))\n",
    "\n",
    "# Evaluate on test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test_encoded)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
